from paddleocr import PaddleOCR
import time
import os
import numpy as np
from typing import List, Dict, Any
import numpy as np
class PaddleOCRService:
    _instance = None
    ocr_engine = None

    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            print("ğŸš€ [Maas Service] æ­£åœ¨åˆå§‹åŒ– PaddleOCR æœåŠ¡...")
            cls._instance = super(PaddleOCRService, cls).__new__(cls)
            cls._instance.initialize_model()
        return cls._instance

    def initialize_model(self):
        try:
            self.ocr_engine = PaddleOCR(
                # æ ¸å¿ƒè®¾ç½®ï¼šå…³é—­è§’åº¦åˆ†ç±»ï¼ŒæŒ‡å®šè¯­è¨€
                use_angle_cls=False,
                lang="ch",
                
                # --- å…³é”®è®¾ç½® ---
                # 1. ç¦ç”¨æ–‡æ¡£æ–¹å‘åˆ†ç±» (è§£å†³ No valid model found æŠ¥é”™)
                use_doc_orientation_classify=False,
                
                # 2. ç¦ç”¨æ–‡æ¡£çŸ«æ­£ (åŠ å¿«é€Ÿåº¦ï¼Œå‡å°‘æ¨¡å‹ä¾èµ–)
                use_doc_unwarping=False,
                
                # æ³¨æ„ï¼šå·²åˆ é™¤ use_textline_orientation å‚æ•°ä»¥è§£å†³äº’æ–¥æŠ¥é”™
                
                # æŒ‡å®šæ¨¡å‹ç‰ˆæœ¬ï¼Œç¡®ä¿ç¨³å®šæ€§
                ocr_version='PP-OCRv4' 
            )
        except Exception as e:
            print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise e
    # ä¿®æ”¹ ocr.py ä¸­çš„ predict_text_only æ–¹æ³•
    def predict_text_only(self, input_path: str) -> Dict[str, Any]:
        if not os.path.exists(input_path):
            return {"error": f"æœªæ‰¾åˆ°æ–‡ä»¶: {input_path}", "success": False}

        start_predict = time.time()
        try:
            result = self.ocr_engine.predict(input_path)
        except Exception as e:
            return {"error": f"æ¨ç†é”™è¯¯: {e}", "success": False}
        end_predict = time.time()
        
        raw_items = []
        
        if result:
            res_list = list(result)
            if len(res_list) > 0:
                data = res_list[0]
                texts = data.get('rec_texts', [])
                boxes = data.get('dt_polys', [])
                
                for text, box in zip(texts, boxes):
                    box_np = np.array(box) 
                    
                    y_min = np.min(box_np[:, 1])
                    y_max = np.max(box_np[:, 1])
                    y_center = (y_min + y_max) / 2
                    x_left = np.min(box_np[:, 0])

                    raw_items.append({
                        "text": text,
                        "cy": y_center,  # ä¸­å¿ƒç‚¹
                        "cx": x_left,    # å·¦ä¾§ç‚¹
                        "y_min": y_min,  # [æ–°å¢] é¡¶éƒ¨è¾¹ç•Œ
                        "y_max": y_max   # [æ–°å¢] åº•éƒ¨è¾¹ç•Œ
                    })
        
        structured_menu = self._post_process_menu(raw_items)
        predict_duration = end_predict - start_predict
        
        return {
            "success": True,
            "inference_time_seconds": predict_duration,
            "menu_items": structured_menu
        }
    # ä¿®æ”¹ ocr.py ä¸­çš„ _post_process_menu æ–¹æ³•
    def _post_process_menu(self, items: List[Dict]) -> List[Dict]:
        """
        å…¨å±€ç©ºé—´é”šç‚¹æœç´¢ (Global Spatial Anchor Search):
        
        æ ¸å¿ƒæ€æƒ³ï¼š
        ä¸å†æŒ‰è¡Œé¡ºåºè¯»å–ï¼Œè€Œæ˜¯å°† OCR ç»“æœè§†ä¸ºäºŒç»´ç‚¹é˜µã€‚
        1. æ‰¾å‡ºæ‰€æœ‰â€œä»·æ ¼é”šç‚¹â€ã€‚
        2. æ‰¾å‡ºæ‰€æœ‰â€œæ–‡æœ¬å€™é€‰å—â€ã€‚
        3. å¯¹äºæ¯ä¸ªä»·æ ¼ï¼Œåœ¨å…¨å±€èŒƒå›´å†…å¯»æ‰¾â€œå‚ç›´è·ç¦»æœ€è¿‘â€çš„æ–‡æœ¬å—ä½œä¸ºå…¶èœåã€‚
        """
        if not items:
            return []

        # --- 1. é¢„å¤„ç†ï¼šå‡ ä½•è¡Œåˆå¹¶ (Geometry Line Merge) ---
        # ç›®çš„ï¼šå°†ç¢ç‰‡åŒ–çš„å•è¯ (å¦‚ "Kung", "Pao", "Chicken") åˆå¹¶æˆä¸€ä¸ªå®Œæ•´çš„æ–‡æœ¬å—ã€‚
        # è¿™æ­¥å¿…é¡»ä¿ç•™ï¼Œå¦åˆ™â€œè·ç¦»æœ€è¿‘â€çš„å¯èƒ½åªæ˜¯ "Chicken" è¿™ä¸ªè¯ï¼Œè€Œä¸æ˜¯æ•´é“èœåã€‚
        items.sort(key=lambda k: k['cy'])
        lines = []
        for item in items:
            added = False
            if lines:
                last_line = lines[-1]
                l_min = sum([i['y_min'] for i in last_line]) / len(last_line)
                l_max = sum([i['y_max'] for i in last_line]) / len(last_line)
                
                intersection = max(0, min(l_max, item['y_max']) - max(l_min, item['y_min']))
                union = (item['y_max'] - item['y_min'])
                if union > 0 and (intersection / union) > 0.4:
                    last_line.append(item)
                    added = True
            if not added:
                lines.append([item])

        # --- 2. æ„å»ºâ€œä»·æ ¼é›†åˆâ€ä¸â€œæ–‡æœ¬é›†åˆâ€ ---
        price_anchors = []    # å­˜æ”¾ä»·æ ¼ä¿¡æ¯çš„å—
        text_candidates = []  # å­˜æ”¾æ½œåœ¨èœåçš„å—
        
        import re
        
        def is_price_token(s):
            clean = s.replace('$', '').replace('starting at', '').strip()
            if not clean: return False
            return (any(char.isdigit() for char in clean) and len(clean) < 8)

        for line_items in lines:
            # æå–è¯¥è¡Œçš„å±æ€§
            text_parts = []
            has_price_in_line = False
            
            # è®¡ç®—è¯¥è¡Œçš„å‡ ä½•ä¸­å¿ƒ Y
            avg_y = sum([i['cy'] for i in line_items]) / len(line_items)

            for item in line_items:
                txt = item['text']
                if is_price_token(txt):
                    has_price_in_line = True
                else:
                    text_parts.append(txt)
            
            clean_text = " ".join(text_parts).strip()
            # æ¸…ç†è¡Œé¦–ç¼–å·
            clean_text = re.sub(r'^[\d\.]+\s+', '', clean_text)
            
            # æ„é€ è¡Œå¯¹è±¡
            line_obj = {
                "text": clean_text,
                "y": avg_y,
                "has_price": has_price_in_line
            }

            # åˆ†ç±»å½’æ¡£
            # A. å¦‚æœè¿™ä¸€è¡Œæœ‰æ–‡æœ¬ï¼Œå®ƒå°±æ˜¯æ½œåœ¨çš„èœåå€™é€‰è€…
            if clean_text:
                text_candidates.append(line_obj)
            
            # B. å¦‚æœè¿™ä¸€è¡Œæœ‰ä»·æ ¼ï¼Œå®ƒå°±æ˜¯ä¸€ä¸ªæœç´¢é”šç‚¹
            if has_price_in_line:
                price_anchors.append(line_obj)

        # --- 3. æ ¸å¿ƒé€»è¾‘ï¼šæœ€è¿‘é‚»æœç´¢ (Nearest Neighbor) ---
        found_dishes = set() # ä½¿ç”¨é›†åˆè‡ªåŠ¨å»é‡
        
        # é»‘åå•
        IGNORE_EXACT = ["SALAD", "SIDES", "DRINKS", "NEW!", "RICE BOWL", "EXTRAS"]

        for p_anchor in price_anchors:
            best_match_text = None
            
            # æƒ…å†µ 1: åŒè¡ŒåŒ¹é… (Horizontal Match)
            # ä»·æ ¼é”šç‚¹æœ¬èº«å°±åŒ…å«æ–‡æœ¬ -> è·ç¦»ä¸º 0 -> ç›´æ¥é”å®š
            if p_anchor['text']:
                best_match_text = p_anchor['text']
            
            # æƒ…å†µ 2: å¼‚è¡ŒåŒ¹é… (Vertical Match)
            # ä»·æ ¼é”šç‚¹åªæœ‰ä»·æ ¼ (å¦‚ "$12.99") -> åœ¨æ‰€æœ‰æ–‡æœ¬å€™é€‰è€…ä¸­æ‰¾æœ€è¿‘çš„
            elif text_candidates:
                # ä½¿ç”¨ min å‡½æ•°å¯»æ‰¾å‚ç›´è·ç¦» abs(y1 - y2) æœ€å°çš„è¡Œ
                closest_candidate = min(text_candidates, key=lambda c: abs(c['y'] - p_anchor['y']))
                
                # å®‰å…¨é˜ˆå€¼æ£€æŸ¥ï¼šé˜²æ­¢åŒ¹é…åˆ°é¡µè„šæˆ–å¤ªè¿œçš„åœ°æ–¹ (æ¯”å¦‚ > 100px)
                if abs(closest_candidate['y'] - p_anchor['y']) < 120:
                    best_match_text = closest_candidate['text']

            # --- ä¿å­˜ç»“æœ ---
            if best_match_text:
                # è¿‡æ»¤åƒåœ¾è¯
                if best_match_text not in IGNORE_EXACT and len(best_match_text) > 2:
                    found_dishes.add(best_match_text)

        # --- 4. æ ¼å¼åŒ–è¾“å‡º ---
        # å°† set è½¬å› list dict
        result_list = [{"dish": name} for name in found_dishes]
        
        return result_list
    

paddle_service = PaddleOCRService()